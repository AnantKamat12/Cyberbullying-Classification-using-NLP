{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCzl7NWdNk6Q",
        "outputId": "8f001ec6-9639-44ad-df0a-e34a722e796e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "500MBsIPNnC8",
        "outputId": "3f40ec3b-2a11-411e-e629-0450450a72db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m-D-6d9bOCrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kUKYnbWAOGso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Uninstall the libraries causing conflicts (to be safe)\n",
        "!pip uninstall -y transformers datasets\n",
        "\n",
        "# 2. Install datasets and transformers, ignoring deep dependencies that cause the error\n",
        "!pip install datasets --no-deps\n",
        "!pip install transformers[tf] --no-deps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCUbKK8qOJFI",
        "outputId": "441039d9-57a2-4b7a-daea-baaa8335bcad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.57.1\n",
            "Uninstalling transformers-4.57.1:\n",
            "  Successfully uninstalled transformers-4.57.1\n",
            "Found existing installation: datasets 4.4.0\n",
            "Uninstalling datasets-4.4.0:\n",
            "  Successfully uninstalled datasets-4.4.0\n",
            "Collecting datasets\n",
            "  Using cached datasets-4.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Using cached datasets-4.4.0-py3-none-any.whl (511 kB)\n",
            "Installing collected packages: datasets\n",
            "Successfully installed datasets-4.4.0\n",
            "Collecting transformers[tf]\n",
            "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
            "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-4.57.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/My_works/DATASCIENCE /datasetoftweets.zip\")"
      ],
      "metadata": {
        "id": "YNMqQxnLOejG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns=['tweet','type']"
      ],
      "metadata": {
        "id": "QqU_yGAmPbm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['tweet']=df['tweet'].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "j0msYrkuPdaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "T69iHY99Pnm8",
        "outputId": "166cfb4d-74b2-4621-ad47-5bbd0249a760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               tweet               type\n",
              "0  in other words #katandandre, your food was cra...  not_cyberbullying\n",
              "1  why is #aussietv so white? #mkr #theblock #ima...  not_cyberbullying\n",
              "2  @xochitlsuckkks a classy whore? or more red ve...  not_cyberbullying\n",
              "3  @jason_gio meh. :p  thanks for the heads up, b...  not_cyberbullying\n",
              "4  @rudhoeenglish this is an isis account pretend...  not_cyberbullying"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-316fe112-b6d2-4c16-a489-789a0f34197b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in other words #katandandre, your food was cra...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>why is #aussietv so white? #mkr #theblock #ima...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@xochitlsuckkks a classy whore? or more red ve...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@jason_gio meh. :p  thanks for the heads up, b...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@rudhoeenglish this is an isis account pretend...</td>\n",
              "      <td>not_cyberbullying</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-316fe112-b6d2-4c16-a489-789a0f34197b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-316fe112-b6d2-4c16-a489-789a0f34197b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-316fe112-b6d2-4c16-a489-789a0f34197b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-26da24db-8578-41e2-9434-edfbef87fd1e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-26da24db-8578-41e2-9434-edfbef87fd1e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-26da24db-8578-41e2-9434-edfbef87fd1e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 47692,\n  \"fields\": [\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 45991,\n        \"samples\": [\n          \"humane behaviour leaving jihadi without harms, injuries>not for next time can we expect this from muslims-jihadis-terrorists invaders-predators-barbarians conspiring ghazwa-e-hind dar-ul-harb jihad against hindus-hindutva-hindusthan-humanity &amp; world #jihad_jihadi_mukt_bharat\",\n          \"girls who bullied me in high school are romances now and im gay\",\n          \"@michaeldelbay last retweet\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"not_cyberbullying\",\n          \"gender\",\n          \"ethnicity\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jhLuygGkPx59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#skipping Removal of Special characters for BERT as it is pretrained to handle such character"
      ],
      "metadata": {
        "id": "YcVKp1TGP-W7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming your text column is 'tweet' and your multiclass column is 'type'\n",
        "TEXT_COLUMN = 'tweet'\n",
        "LABEL_COLUMN = 'type'\n",
        "\n",
        "# 1. Multiclass Label Encoding (Convert string classes to integers 0-5)\n",
        "label_encoder = LabelEncoder()\n",
        "df['target_id'] = label_encoder.fit_transform(df[LABEL_COLUMN])\n",
        "\n",
        "# Save the target names and number of classes\n",
        "unique_classes = label_encoder.classes_\n",
        "num_classes = len(unique_classes)\n",
        "\n",
        "# 2. Stratified Train-Test Split (20% for testing)\n",
        "X_train_text, X_test_text, y_train_id, y_test_id = train_test_split(\n",
        "    df[TEXT_COLUMN],\n",
        "    df['target_id'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['target_id'] # Ensures each class has proportional representation in the split\n",
        ")\n",
        "\n",
        "print(\"Label Encoding and Stratified Split Complete.\")\n",
        "print(f\"Total classes: {num_classes}. Class names: {unique_classes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcR8nLSgQGMz",
        "outputId": "ceed0092-e46a-4cbe-80bd-b5f61ff1f995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Encoding and Stratified Split Complete.\n",
            "Total classes: 6. Class names: ['age' 'ethnicity' 'gender' 'not_cyberbullying' 'other_cyberbullying'\n",
            " 'religion']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import tensorflow as tf\n",
        "\n",
        "# --- 1. Load Pre-trained Tokenizer ---\n",
        "MODEL_NAME = 'bert-base-uncased'\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "MAX_LENGTH = 100 # We will use a sequence length of 100 for BERT\n",
        "\n",
        "def tokenize_data(texts, labels):\n",
        "    # Apply tokenization, padding, and truncation in one step\n",
        "    encodings = bert_tokenizer(\n",
        "        texts.tolist(),\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=MAX_LENGTH\n",
        "    )\n",
        "\n",
        "    # Convert encodings and labels to a TensorFlow Dataset\n",
        "    return tf.data.Dataset.from_tensor_slices((\n",
        "        dict(encodings),\n",
        "        labels.values\n",
        "    ))\n",
        "\n",
        "# --- 3. Create Datasets ---\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = tokenize_data(X_train_text, y_train_id).shuffle(1000).batch(BATCH_SIZE)\n",
        "test_dataset = tokenize_data(X_test_text, y_test_id).batch(BATCH_SIZE)\n",
        "\n",
        "print(\"\\nBERT Tokenization and Dataset Creation Complete.\")\n",
        "print(f\"BERT will use sequences of length: {MAX_LENGTH} tokens.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87fk4Ce9QPdY",
        "outputId": "c2b554d3-4a87-4f19-cea4-f480dd7e23df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BERT Tokenization and Dataset Creation Complete.\n",
            "BERT will use sequences of length: 100 tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFBertForSequenceClassification, create_optimizer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "MODEL_NAME = 'bert-base-uncased'\n",
        "num_classes = 6 # Assuming you have 6 classes\n",
        "bert_model = TFBertForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=num_classes,\n",
        "    from_pt=False,\n",
        "    use_safetensors=False\n",
        ")\n",
        "\n",
        "# --- 2. Define Learning Rate and Optimizer Steps ---\n",
        "# These parameters are now required for the create_optimizer utility.\n",
        "EPOCHS_BERT = 3\n",
        "BATCH_SIZE = 32 # Must match the batch size from your dataset creation\n",
        "total_train_steps = tf.data.experimental.cardinality(train_dataset).numpy() * EPOCHS_BERT\n",
        "\n",
        "# 3. Define the BERT-Specific Optimizer\n",
        "# This utility creates the Adam optimizer with weight decay, essential for BERT fine-tuning.\n",
        "# We set the learning rate to the standard 5e-5.\n",
        "bert_optimizer, bert_lr_scheduler = create_optimizer(\n",
        "    init_lr=5e-5,\n",
        "    num_warmup_steps=0, # Typically used for large pretraining, not simple fine-tuning\n",
        "    num_train_steps=total_train_steps\n",
        ")\n",
        "\n",
        "\n",
        "# --- 4. Compile the Model ---\n",
        "bert_model.compile(\n",
        "    # PASS THE OPTIMIZER OBJECT CREATED BY THE UTILITY\n",
        "    optimizer=bert_optimizer,\n",
        "    # Loss remains the same\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"BERT Classification Model Architecture Defined and Compiled Successfully.\")\n",
        "bert_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp9qgpq6SduR",
        "outputId": "9bb2dcca-9e7e-4bd4-f078-c3a62a0cf8a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Classification Model Architecture Defined and Compiled Successfully.\n",
            "Model: \"tf_bert_for_sequence_classification_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  109482240 \n",
            "                                                                 \n",
            " dropout_303 (Dropout)       multiple                  0 (unused)\n",
            "                                                                 \n",
            " classifier (Dense)          multiple                  4614      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109486854 (417.66 MB)\n",
            "Trainable params: 109486854 (417.66 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78a0320a"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. Remount Drive (Safety check) ---\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- 2. Training Setup (No Callbacks) ---\n",
        "# Assuming bert_model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor are available\n",
        "EPOCHS_BERT = 3\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Define Base Path for Saving Models after each epoch\n",
        "DRIVE_TARGET_DIR = '/content/drive/MyDrive/My_works/DATASCIENCE'\n",
        "if not os.path.exists(DRIVE_TARGET_DIR):\n",
        "    os.makedirs(DRIVE_TARGET_DIR)\n",
        "\n",
        "print(f\"\\nStarting BERT Fine-Tuning for fixed {EPOCHS_BERT} epochs (No Callbacks)...\")\n",
        "print(\"We will manually save the model after each epoch.\")\n",
        "\n",
        "# --- 3. Manual Training Loop (Iterating over epochs) ---\n",
        "for epoch in range(EPOCHS_BERT):\n",
        "    print(f\"\\n--- Starting Epoch {epoch + 1}/{EPOCHS_BERT} ---\")\n",
        "\n",
        "    # Train for one epoch\n",
        "    history = bert_model.fit(\n",
        "        X_train_tensor,\n",
        "        y_train_tensor,\n",
        "        epochs=1,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        validation_data=(X_test_tensor, y_test_tensor),\n",
        "        # Start training from the current state (Epoch 0 is where we start the loop)\n",
        "        initial_epoch=epoch\n",
        "    )\n",
        "\n",
        "    # Manual Save after each epoch completes\n",
        "    EPOCH_MODEL_NAME = f'bert_epoch_{epoch + 1}_model.h5'\n",
        "    EPOCH_SAVE_PATH = os.path.join(DRIVE_TARGET_DIR, EPOCH_MODEL_NAME)\n",
        "\n",
        "    # Save the entire model (architecture + weights) for easy reloading\n",
        "    bert_model.save(EPOCH_SAVE_PATH)\n",
        "    print(f\"✅ Saved model for Epoch {epoch + 1} to Drive.\")\n",
        "\n",
        "print(\"\\nBERT Fine-Tuning Complete. Three model versions saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "AICI29SNUdlN",
        "outputId": "f74e49d7-5dd9-4b68-c0a6-2484595e7a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Starting BERT Fine-Tuning for fixed 3 epochs (No Callbacks)...\n",
            "We will manually save the model after each epoch.\n",
            "\n",
            "--- Starting Epoch 1/3 ---\n",
            "1193/1193 [==============================] - 863s 674ms/step - loss: 0.4305 - accuracy: 0.8278 - val_loss: 0.3281 - val_accuracy: 0.8645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1000088863.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Save the entire model (architecture + weights) for easy reloading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mbert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH_SAVE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✅ Saved model for Epoch {epoch + 1} to Drive.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tf_keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         ):\n\u001b[0;32m--> 151\u001b[0;31m             raise NotImplementedError(\n\u001b[0m\u001b[1;32m    152\u001b[0m                 \u001b[0;34m\"Saving the model to HDF5 format requires the model to be a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;34m\"Functional model or a Sequential model. It does not work for \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the bert_model is still loaded in your current session's memory after the failed save.\n",
        "from sklearn.metrics import classification_report # Import classification_report\n",
        "\n",
        "# --- 1. Define Evaluation Function (using a dummy path since we are testing memory) ---\n",
        "def evaluate_current_bert_model(model_instance, unique_classes):\n",
        "    print(\"\\n--- Evaluating BERT Model currently in memory (End of Epoch 1) ---\")\n",
        "\n",
        "    # We must compile the loaded model for prediction setup\n",
        "    model_instance.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Predict on the test data (X_test_tensor)\n",
        "    y_pred_logits = model_instance.predict(X_test_tensor, verbose=0, batch_size=64).logits\n",
        "    y_pred_classes = np.argmax(y_pred_logits, axis=1)\n",
        "\n",
        "    # Calculate report\n",
        "    report = classification_report(\n",
        "        y_test_tensor, y_pred_classes, target_names=unique_classes, output_dict=True\n",
        "    )\n",
        "\n",
        "    # Store key metrics\n",
        "    metrics = {\n",
        "        'Macro F1': report['macro avg']['f1-score'],\n",
        "        'Not Cyberbullying F1': report['not_cyberbullying']['f1-score'],\n",
        "        'Other Cyberbullying F1': report['other_cyberbullying']['f1-score'],\n",
        "        'Overall Accuracy': report['accuracy']\n",
        "    }\n",
        "\n",
        "    print(f\"Overall Accuracy: {metrics['Overall Accuracy']:.4f}\")\n",
        "    print(f\"Macro F1: {metrics['Macro F1']:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test_tensor, y_pred_classes, target_names=unique_classes))\n",
        "    return metrics\n",
        "\n",
        "# Run the evaluation\n",
        "metrics_epoch_1 = evaluate_current_bert_model(bert_model, unique_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMePWrQ3Y-4C",
        "outputId": "4041a7dd-ba98-4308-d6dd-2ade3230f816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating BERT Model currently in memory (End of Epoch 1) ---\n",
            "Overall Accuracy: 0.8645\n",
            "Macro F1: 0.8630\n",
            "Classification Report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                age       0.99      0.98      0.98      1598\n",
            "          ethnicity       0.99      0.97      0.98      1592\n",
            "             gender       0.87      0.89      0.88      1595\n",
            "  not_cyberbullying       0.68      0.65      0.66      1589\n",
            "other_cyberbullying       0.70      0.71      0.71      1565\n",
            "           religion       0.94      0.98      0.96      1600\n",
            "\n",
            "           accuracy                           0.86      9539\n",
            "          macro avg       0.86      0.86      0.86      9539\n",
            "       weighted avg       0.86      0.86      0.86      9539\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFBertForSequenceClassification, create_optimizer\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. Remount Drive and Setup Paths ---\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_TARGET_DIR = '/content/drive/MyDrive/My_works/DATASCIENCE'\n",
        "HISTORY_SAVE_PATH = os.path.join(DRIVE_TARGET_DIR, 'bert_training_history.pkl')\n",
        "\n",
        "# --- 2. Reload Fresh BERT Model (Resets weights to pre-trained state) ---\n",
        "# Assuming num_classes, X_train_tensor, and X_test_tensor are available\n",
        "MODEL_NAME = 'bert-base-uncased'\n",
        "EPOCHS_BERT_HISTORY = 1 # Only run one epoch for history collection\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "bert_model_fresh = TFBertForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=num_classes,\n",
        "    from_pt=False,\n",
        "    use_safetensors=False\n",
        ")\n",
        "\n",
        "# --- 3. Define and Compile with Fixed Optimizer Utility ---\n",
        "# These calculations are needed for the optimizer utility\n",
        "total_train_steps = tf.data.experimental.cardinality(train_dataset).numpy() * EPOCHS_BERT_HISTORY\n",
        "bert_optimizer_fixed, _ = create_optimizer(\n",
        "    init_lr=5e-5,\n",
        "    num_warmup_steps=0,\n",
        "    num_train_steps=total_train_steps\n",
        ")\n",
        "\n",
        "bert_model_fresh.compile(\n",
        "    optimizer=bert_optimizer_fixed,\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# --- 4. Train and Collect History ---\n",
        "print(f\"\\nStarting FRESH BERT Training run to collect history plot data (1 Epoch)...\")\n",
        "\n",
        "# Training fit call\n",
        "history_bert_plot = bert_model_fresh.fit(\n",
        "    X_train_tensor,\n",
        "    y_train_tensor,\n",
        "    epochs=EPOCHS_BERT_HISTORY,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=(X_test_tensor, y_test_tensor),\n",
        ")\n",
        "\n",
        "# --- 5. Save History Plot Data ---\n",
        "with open(HISTORY_SAVE_PATH, 'wb') as file:\n",
        "    pickle.dump(history_bert_plot.history, file)\n",
        "\n",
        "print(f\"\\n✅ BERT Training History for plot successfully saved to Drive: {HISTORY_SAVE_PATH}\")\n",
        "print(\"You now have all necessary files to complete your project report.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVeqYt6aVY-X",
        "outputId": "a7f0a6f7-0b6f-4463-d5ef-8a6f6dff760b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting FRESH BERT Training run to collect history plot data (1 Epoch)...\n",
            "1193/1193 [==============================] - 866s 683ms/step - loss: 0.4212 - accuracy: 0.8332 - val_loss: 0.3236 - val_accuracy: 0.8682\n",
            "\n",
            "✅ BERT Training History for plot successfully saved to Drive: /content/drive/MyDrive/My_works/DATASCIENCE/bert_training_history.pkl\n",
            "You now have all necessary files to complete your project report.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Assuming bert_model_fresh (the local variable from the last cell) is the model to evaluate.\n",
        "# Assuming X_test_tensor, y_test_tensor, and unique_classes are available.\n",
        "\n",
        "def evaluate_bert_champion(model_instance, unique_classes):\n",
        "    print(\"\\n--- Final Evaluation: BERT Champion Model ---\")\n",
        "\n",
        "    # We must compile the loaded model for prediction setup\n",
        "    # NOTE: It was compiled before training, but compiling again ensures consistency.\n",
        "    model_instance.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Predict on the test data (X_test_tensor)\n",
        "    y_pred_logits = model_instance.predict(X_test_tensor, verbose=0, batch_size=64).logits\n",
        "    y_pred_classes = np.argmax(y_pred_logits, axis=1)\n",
        "\n",
        "    # Calculate report\n",
        "    report = classification_report(\n",
        "        y_test_tensor, y_pred_classes, target_names=unique_classes, output_dict=True\n",
        "    )\n",
        "\n",
        "    # Store key metrics\n",
        "    metrics = {\n",
        "        'Macro F1': report['macro avg']['f1-score'],\n",
        "        'Not Cyberbullying F1': report['not_cyberbullying']['f1-score'],\n",
        "        'Other Cyberbullying F1': report['other_cyberbullying']['f1-score'],\n",
        "        'Overall Accuracy': report['accuracy']\n",
        "    }\n",
        "\n",
        "    print(f\"Overall Accuracy: {metrics['Overall Accuracy']:.4f}\")\n",
        "    print(f\"Macro F1: {metrics['Macro F1']:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test_tensor, y_pred_classes, target_names=unique_classes))\n",
        "    return metrics\n",
        "\n",
        "# Run the final evaluation\n",
        "final_bert_metrics = evaluate_bert_champion(bert_model_fresh, unique_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X3CMYNBcYf6",
        "outputId": "6c535acf-283e-49bd-9bc4-831e6f41dee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Evaluation: BERT Champion Model ---\n",
            "Overall Accuracy: 0.8682\n",
            "Macro F1: 0.8646\n",
            "Classification Report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                age       0.99      0.98      0.98      1598\n",
            "          ethnicity       0.98      0.97      0.98      1592\n",
            "             gender       0.88      0.90      0.89      1595\n",
            "  not_cyberbullying       0.77      0.55      0.64      1589\n",
            "other_cyberbullying       0.66      0.82      0.73      1565\n",
            "           religion       0.94      0.98      0.96      1600\n",
            "\n",
            "           accuracy                           0.87      9539\n",
            "          macro avg       0.87      0.87      0.86      9539\n",
            "       weighted avg       0.87      0.87      0.87      9539\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "\n",
        "# --- 1. Remount Drive (Safety Check) ---\n",
        "# Ensure your drive is mounted before saving\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- 2. Define File Path on Drive ---\n",
        "DRIVE_TARGET_DIR = '/content/drive/MyDrive/My_works/DATASCIENCE'\n",
        "if not os.path.exists(DRIVE_TARGET_DIR):\n",
        "    os.makedirs(DRIVE_TARGET_DIR)\n",
        "\n",
        "CHAMPION_WEIGHTS_NAME = 'bert_champion_epoch_1_weights.h5'\n",
        "SAVE_PATH = os.path.join(DRIVE_TARGET_DIR, CHAMPION_WEIGHTS_NAME)\n",
        "\n",
        "# --- 3. Save Weights Manually ---\n",
        "# Assuming the bert_model is currently holding the Epoch 1 weights in memory\n",
        "try:\n",
        "    # Use the correct save_weights method for the subclassed BERT model\n",
        "    bert_model_fresh.save_weights(SAVE_PATH)\n",
        "    print(f\"✅ CHAMPION BERT weights (Epoch 1) successfully saved to Drive: {SAVE_PATH}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ CRITICAL ERROR: Could not save weights. {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_oh9a8fifTa",
        "outputId": "007b36a4-de78-4d77-f906-dd2a11d2c160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ CHAMPION BERT weights (Epoch 1) successfully saved to Drive: /content/drive/MyDrive/My_works/DATASCIENCE/bert_champion_epoch_1_weights.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6GHjEuNRjMu3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}