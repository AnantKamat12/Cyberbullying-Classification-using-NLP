# Cyberbullying Detection Using NLP (NB â†’ BiLSTM â†’ BERT)

This project builds a complete multi-class cyberbullying detection pipeline using **classical ML**, **deep learning**, and **transformers**.  
It analyzes a Kaggle dataset of **47,000+ tweets** and compares three models:

âœ… Multinomial Naive Bayes  
âœ… BiLSTM  
âœ… BERT (Transformer â€“ Final Model)

---

## ğŸ“Œ Dataset
- **47,000+ tweets**  
- **6 classes**:  
  - age  
  - ethnicity  
  - gender  
  - religion  
  - other\_cyberbullying  
  - not\_cyberbullying  
- Highly imbalanced dataset â†’ required careful evaluation

---

## ğŸ”§ Workflow Overview

### 1ï¸âƒ£ Data Cleaning
- Lowercasing  
- Removal of URLs, mentions, hashtags, emojis  
- Stopword removal  
- Lemmatization  
- Duplicate removal  
- Trainâ€“test split with stratification  

### 2ï¸âƒ£ Feature Engineering
- TFâ€“IDF (20k max features) for classical models  
- Tokenization + padding + attention masking for BERT  

---

## ğŸ§ª Model 1 â€” Multinomial Naive Bayes (Baseline)
- Features: **TFâ€“IDF**  
- **Accuracy:** 75.38%  
- **Macro F1:** 0.73  

Performs well on frequent classes (age, ethnicity, religion)  
Struggles on **not\_cyberbullying** due to dataset imbalance.

---

## ğŸ§¬ Model 2 â€” BiLSTM (Deep Learning)
- Embedding layer + Bidirectional LSTM + dropout regularization  
- Optimizer: Adam  
- Trained for multiple epochs  

**Performance:**
- **Accuracy:** 83%  
- **Macro F1:** 0.83  

Major improvement over NB, especially in minority classes.

---

## ğŸ¤– Model 3 â€” BERT (Transformer â€“ Final Model)
Model used: **bert-base-uncased**

- Tokenized with WordPiece tokenizer  
- Trained with AdamW + warmup schedule  
- Max sequence length: 128  

**Performance:**  
- **Accuracy:** 86.82%  
- **Macro F1:** 0.8646  

Best precisionâ€“recall balance across all 6 classes.

---

## ğŸ“Š Model Comparison

| Model                     | Accuracy | Macro F1 |
|--------------------------|----------|----------|
| Multinomial NB           | 75.38%   | 0.73     |
| BiLSTM                   | 83%      | 0.83     |
| BERT (Final)             | 86.82%   | 0.8646   |

---

## âœ… Key Takeaways
- BERT significantly improves minority-class F1 scores.  
- NB serves as a fast, interpretable baseline but struggles with imbalance.  
- BiLSTM hits a strong middle ground with better sequence understanding.  
- Transformers remain the most powerful for context-heavy text classification.

---

## ğŸ“ Repository Structure
